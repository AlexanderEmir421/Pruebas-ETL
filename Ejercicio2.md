
# ğŸ§ª Ejercicio 2 â€“ Consumo de API del BCRA y carga incremental en Supabase

Este mÃ³dulo resuelve el segundo ejercicio de la prueba tÃ©cnica: **extraer datos de cotizaciones de monedas desde la API pÃºblica del BCRA**, normalizarlos y almacenarlos en Supabase, con una automatizaciÃ³n semanal vÃ­a Airflow.

---

## ğŸ§  Â¿QuÃ© pedÃ­a el ejercicio?

Extraer informaciÃ³n histÃ³rica de tipo de cambio desde una fuente pÃºblica (API del BCRA) y almacenarla en una base nube.

Mi enfoque fue diseÃ±ar una estrategia que detecte si ya existen datos cargados por moneda, y en funciÃ³n de eso, decidir si hacer:

- ğŸ”„ **Carga inicial**: Ãºltimos 30 dÃ­as (para no saturar)
- â™»ï¸ **Carga incremental**: desde la Ãºltima fecha cargada

---

## ğŸ§© DiseÃ±o general

- ğŸ“¡ **Fuente**: API pÃºblica del BCRA (`/Cotizaciones/{moneda}`)
- ğŸ§° **Proceso**: NormalizaciÃ³n de datos, control de duplicados, carga por lotes (`batch`)
- â˜ï¸ **Destino**: Tabla `cotizaciones` en Supabase
- ğŸ” **OrquestaciÃ³n**: DAG de Airflow semanal

---

## ğŸ› ï¸ Estructura de la tabla destino

```sql
cotizaciones (
    moneda TEXT,
    tipo_cambio FLOAT,
    fecha DATE
)
```

La normalizaciÃ³n asegura que:

- Se ignoren entradas sin `detalle`
- Se filtren cotizaciones con valor 0
- Los datos estÃ©n listos para anÃ¡lisis directo

---

## âš™ï¸ LÃ³gica de carga

### ğŸ”„ NormalizaciÃ³n

```python
def normalizar(registro):
    if not registro.get('detalle'):
        return None
    detalle = registro['detalle'][0].copy()
    tipo_cambio = float(detalle['tipoCotizacion'])
    if tipo_cambio == 0:
        return None
    return {
        'moneda': detalle['codigoMoneda'],
        'tipo_cambio': tipo_cambio,
        'fecha': registro['fecha']
    }
```

---

### ğŸš€ Carga inicial

Consulta los Ãºltimos 30 dÃ­as para las primeras 5 monedas.

```python
divisas = requests.get(url_divisas).json()['results']
for i, moneda in pd.DataFrame(divisas).head(5).iterrows():
    historial = get_api(fechadesde, fechahasta, moneda['codigo'])
    loadsupabase(pd.DataFrame(historial))
```

> Se activa si **la tabla estÃ¡ vacÃ­a**

---

### â™»ï¸ Carga incremental

Para cada moneda, consulta la Ãºltima fecha cargada y pide datos nuevos.

```python
fecha_desde = supabase.table('cotizaciones')\
    .select("fecha")\
    .eq("moneda", moneda['codigo'])\
    .order("fecha", desc=True)\
    .limit(1)\
    .execute()
```

> Recorre hasta **10 monedas** para validar escalabilidad

---

## ğŸ“… AutomatizaciÃ³n con Airflow

El DAG corre cada lunes a las 00:00. El flujo general es:

1. **Inicio**: Detecta si hay datos en Supabase
2. Si hay â†’ `cargaincremental`
3. Si no hay â†’ `cargainicial`
4. Cierra en `fin`

```python
inicio >> [inicial, incremental]
[inicial, incremental] >> fin
```

### `schedule_interval`

```python
schedule_interval='0 0 * * 1'  # lunes 00:00
```

---

## ğŸ“ˆ Diagrama de Secuencia â€“ Flujo del DAG

```mermaid
sequenceDiagram
    autonumber
    participant Airflow
    participant Supabase
    participant API_BCRA
    participant DAG

    Airflow->>DAG: Ejecuta DAG 'Ejercicio2'
    DAG->>Supabase: Consulta tabla cotizaciones
    alt Si hay datos
        DAG->>DAG: Ejecuta 'cargaincremental'
        loop por cada moneda (hasta 10)
            DAG->>Supabase: Consulta Ãºltima fecha
            DAG->>API_BCRA: Trae cotizaciones nuevas
            API_BCRA-->>DAG: Devuelve JSON
            DAG->>Supabase: Inserta nuevos datos
        end
    else No hay datos
        DAG->>DAG: Ejecuta 'cargainicial'
        loop por cada moneda (hasta 5)
            DAG->>API_BCRA: Trae cotizaciones Ãºltimos 30 dÃ­as
            API_BCRA-->>DAG: Devuelve JSON
            DAG->>Supabase: Inserta datos
        end
    end
    DAG->>Airflow: Termina en 'fin'
```

---

## ğŸ“Š Observabilidad y Logs

Durante la ejecuciÃ³n:

- Se imprime la fecha `desde/hasta` de cada consulta
- Se muestra el contenido recibido desde la API
- Se loguean errores por moneda si los hay
- Se puede monitorear desde la UI de Airflow

---

## âœ… ConclusiÃ³n

Este pipeline permite:

- Mantener actualizada una base nube a partir de datos pÃºblicos
- Detectar automÃ¡ticamente si es necesario cargar desde cero o continuar
- Tener una estructura fÃ¡cil de extender con nuevas monedas o nuevas APIs
- Apoyarse en Airflow para trazabilidad, control de errores y reintentos

---
