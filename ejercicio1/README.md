# ğŸ§ª Ejercicio 1 â€“ ReplicaciÃ³n de Base de Datos (PostgreSQL â†’ Supabase)

Este mÃ³dulo resuelve el primer ejercicio de la prueba tÃ©cnica: replicar datos desde una base transaccional en PostgreSQL hacia una base espejo en la nube (Supabase), con automatizaciÃ³n diaria.

---

## ğŸ§  Â¿QuÃ© pedÃ­a el ejercicio?

La empresa ya cuenta con una base de datos transaccional que registra ventas y productos. Lo que necesitan es una **copia diaria de esa informaciÃ³n** en la nube, para usarla con fines de anÃ¡lisis.

> Mi enfoque fue crear una carga inicial y luego una carga incremental eficiente. Evitar hacer un full refresh todos los dÃ­as es clave para no sobrecargar el sistema.

---

## ğŸ§± Paso 1: Crear el contenedor de PostgreSQL

Se levantÃ³ un contenedor de PostgreSQL en Docker y se configurÃ³ con una **red interna (`bridge`)**. Esto significa que **solo los servicios corriendo dentro del entorno de Docker pueden acceder al Data Warehouse**.

> Se uso para limitar el acceso, y es una buena prÃ¡ctica de encapsulamiento de red para que se comuniquen mis servicios.

---

## ğŸ“¥ Paso 2: Leer los datos desde la base origen

UsÃ© `pandas` para leer los CSV y transformarlos en `DataFrames`. Luego, con `sqlalchemy` + `pymysql` creÃ© una conexiÃ³n entre el contenedor de Python y el contenedor de PostgreSQL.

> Como ambos contenedores estÃ¡n en la misma red, la conexiÃ³n fue directa y sin exponer puertos pÃºblicos.

```python
df = pd.read_csv("csv/FactSales.csv")
df.to_sql("FactSales", con=engine, if_exists="replace", index=False)
```

Los archivos CSV utilizados fueron:

- [`DimDate.csv`](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/-omGFpVSWBIZKFSCxUkBwg/DimDate.csv)
- [`DimCustomerSegment.csv`](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/h_dnxb8yzQyVjeb8oYnm8A/DimCustomerSegment.csv)
- [`DimProduct.csv`](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Y-76u4An3zb5R6HxxFPabA/DimProduct.csv)
- [`FactSales.csv`](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/a8kTjzvpdqzOp46ODatyAA/FactSales.csv)

ğŸ“¸ Despues de haber ejecutado el script se puede apreciar las tablas creadas y sus datos:

![Docker Bridge](https://raw.githubusercontent.com/AlexanderEmir421/Pruebas-ETL/main/docs/docker_postgres_bridge.png)

---

## â˜ï¸ Paso 3: Replicar la base en la nube (Supabase)

Antes se debe crear un proyecto en Supabase, con las tablas cargadas previamente respetando el modelo estrella. Este fue el modelo lÃ³gico interpretado:

```
DimProduct(productid PK, producttype)
DimCustomer(segmentid PK, city)
DimDate(dateid PK, quarter, date, monthname, month, year, quartername)
FactSales(saleid PK, segmentid FK, productid FK, dateid FK, price_per_unit, quantity_sold)
```

ğŸ“¸ MER:

![Modelo ENTIDAD RELACION](./src/MER.png)

---

## ğŸ› ï¸ Tablas auxiliares:
Realizaremos Cargas Incrementales para una mejor eficiencia del codigo ya que se realizan copias todos los dias

### `StgLog`


Esta tabla guarda registros de cuÃ¡ndo se hizo la Ãºltima carga, quÃ© tabla se actualizÃ³ y cuÃ¡l fue el Ãºltimo ID.

> Si `StgLog` estÃ¡ vacÃ­a, el script asume que es la **primera carga**. Si ya tiene datos, realiza una carga **incremental**, ahorrando recursos.

ğŸ“¸

![StgLog](https://raw.githubusercontent.com/AlexanderEmir421/Pruebas-ETL/main/docs/stg_log.png)

---

### `StgCustomer` y `StgProduct`

Estas dos tablas permiten detectar cambios en los datos de dimensiones. En lugar de hacer un full refresh, comparo los registros nuevos y guardo un `estado` (activo/inactivo).

> Esto es Ãºtil si borraron datos en origen. AsÃ­ evito romper la tabla `FactSales`, que necesita esas claves forÃ¡neas.

ğŸ“¸

![StgCustomer](./src/TableStgCustomer.png) ![StgDimProduct](./src/TableStgCustomer.png)

---

## ğŸ”„ Flujo general del script

### Tablas DimDate y FactSales
### Carga inicial

![Carga inicial DimDate y FactSales](./src/PrimerCarga.png)

### Carga incremental 


![Carga incremental DimDate y FactSales](./src/PrimerCargaIncremental.png)



### Tablas DimCustomers y DimProductos
### Carga inicial

![Carga inicial DimDate y FactSales](./src/PrimerCarga.png)

### Carga incremental 

![Carga incremental](https://raw.githubusercontent.com/AlexanderEmir421/Pruebas-ETL/main/docs/etl_flujo_incremental.png)

---


## ğŸ“… AutomatizaciÃ³n con Airflow

El DAG corre todos los dÃ­as y sigue esta lÃ³gica:

1. Consulta `StgLog`
2. Detecta si hay nuevas filas
3. Inserta lo nuevo
4. Actualiza `StgLog` al final

> Aunque podrÃ­a no ser estrictamente necesario, actualizar `StgLog` me sirve para monitorear que todo corriÃ³ bien asegurando que airflow corrio cada dia.

---

## ğŸ§ª Lote de prueba

Se insertÃ³ una fila manual en `FactSales`:

ğŸ“¸

![Insert](https://raw.githubusercontent.com/AlexanderEmir421/Pruebas-ETL/main/docs/insert_fact_test.png)

Y al dÃ­a siguiente, el proceso la detectÃ³ e insertÃ³ correctamente en Supabase:

ğŸ“¸

![Resultado](https://raw.githubusercontent.com/AlexanderEmir421/Pruebas-ETL/main/docs/etl_insert_detectado.png)

---

## âœ… ConclusiÃ³n

Este pipeline permite una replicaciÃ³n confiable y controlada:

- Evita full refresh innecesarios
- Detecta borrados lÃ³gicos
- Deja trazabilidad
- Es liviano para correr a diario