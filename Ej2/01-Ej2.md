
# ðŸ§ª Ejercicio 2 â€“ Consumo de API del BCRA y carga incremental en Supabase

Este mÃ³dulo resuelve el segundo ejercicio de la prueba tÃ©cnica: **extraer datos de cotizaciones de monedas desde la API pÃºblica del BCRA**, normalizarlos y almacenarlos en Supabase, con una automatizaciÃ³n semanal vÃ­a Airflow.

---

## ðŸ§  Â¿QuÃ© pedÃ­a el ejercicio?

Extraer informaciÃ³n histÃ³rica de tipo de cambio desde una fuente pÃºblica (API del BCRA) y almacenarla en una base nube.

Mi enfoque fue diseÃ±ar una estrategia que detecte si ya existen datos cargados por moneda, y en funciÃ³n de eso, decidir si hacer:

- ðŸ”„ **Carga inicial**: Ãºltimos 30 dÃ­as (para no saturar)
- â™»ï¸ **Carga incremental**: desde la Ãºltima fecha cargada

---

## ðŸ§© DiseÃ±o general

- ðŸ“¡ **Fuente**: API pÃºblica del BCRA (`/Cotizaciones/{moneda}`)
- ðŸ§° **Proceso**: NormalizaciÃ³n de datos, carga por lotes (`batch`)
- â˜ï¸ **Destino**: Tabla `cotizaciones` en Supabase
- ðŸ” **OrquestaciÃ³n**: DAG de Airflow semanal

---

## ðŸ› ï¸ Estructura de la tabla destino

```sql
cotizaciones (
    moneda TEXT,
    tipo_cambio FLOAT,
    fecha DATE
)
```

La normalizaciÃ³n asegura que:

- Se ignoren entradas sin `detalle`
- Se filtren cotizaciones con valor 0
- Los datos estÃ©n listos para anÃ¡lisis directo

---
## âš™ï¸ Logica de carga

### Flujo:
![Flujo de carga](/src/CotizacionesPrimerCarga.png)

### ðŸ”„ Reasignar para adaptar la respuesta de la api por las columnas correctas de mi db 

```python
def normalizar(registro):
    if not registro.get('detalle'):
        return None
    detalle = registro['detalle'][0].copy()
    tipo_cambio = float(detalle['tipoCotizacion'])
    if tipo_cambio == 0:
        return None
    return {
        'moneda': detalle['codigoMoneda'],
        'tipo_cambio': tipo_cambio,
        'fecha': registro['fecha']
    }
```

---

### ðŸš€ Carga inicial

Consulta los Ãºltimos 30 dÃ­as para las primeras 5 monedas.

```python
divisas = requests.get(url_divisas).json()['results']
for i, moneda in pd.DataFrame(divisas).head(5).iterrows():
    historial = get_api(fechadesde, fechahasta, moneda['codigo'])
    loadsupabase(pd.DataFrame(historial))
```

> Se activa si **la tabla estÃ¡ vacÃ­a**

---

### â™»ï¸ Carga incremental

Para cada moneda, consulta la Ãºltima fecha cargada y pide datos nuevos.

```python
fecha_desde = supabase.table('cotizaciones')\
    .select("fecha")\
    .eq("moneda", moneda['codigo'])\
    .order("fecha", desc=True)\
    .limit(1)\
    .execute()
```

> Recorre hasta **10 monedas** 

---

## ðŸ“… AutomatizaciÃ³n con Airflow

El DAG corre cada lunes a las 00:00. El flujo general es:

![Flujo DAG](/src/CargaInicialApiFlujo.png)
