# ğŸ§ª Ejercicio 1 â€“ ReplicaciÃ³n de Base de Datos (PostgreSQL â†’ Supabase)

Este mÃ³dulo resuelve el primer ejercicio de la prueba tÃ©cnica: replicar datos desde una base transaccional en PostgreSQL hacia una base espejo en la nube (Supabase), con automatizaciÃ³n diaria.

---

## ğŸ§  Â¿QuÃ© pedÃ­a el ejercicio?

La empresa ya cuenta con una base de datos transaccional que registra ventas y productos. Lo que necesitan es una **copia diaria de esa informaciÃ³n** en la nube, para usarla con fines de anÃ¡lisis.

> Mi enfoque fue crear una carga inicial y luego una carga incremental eficiente. Evitar hacer un full refresh todos los dÃ­as es clave para no sobrecargar el sistema.

---

## ğŸ§± Paso 1: Crear el contenedor de PostgreSQL

Se levantÃ³ un contenedor de PostgreSQL en Docker y se configurÃ³ con una **red interna (`bridge`)**. Esto significa que **solo los servicios corriendo dentro del entorno de Docker pueden acceder al Data Warehouse**.

> Se uso para limitar el acceso, y es una buena prÃ¡ctica de encapsulamiento de red para que se comuniquen mis servicios.

---

## ğŸ“¥ Paso 2: Leer los datos desde la base origen

UsÃ© `pandas` para leer los CSV y transformarlos en `DataFrames`. Luego, con `sqlalchemy` + `pymysql` creÃ© una conexiÃ³n entre el contenedor de Python y el contenedor de PostgreSQL.

> Como ambos contenedores estÃ¡n en la misma red, la conexiÃ³n fue directa y sin exponer puertos pÃºblicos.

```python
df = pd.read_csv(f)# f es el .csv
df.columns = [col.lower() for col in df.columns]#Para mas control convertimos las columnas a minusculas 
table_name = os.path.splitext(os.path.basename(f))[0].lower()#toma el nombre del archivo como nombre de la tabla
df.to_sql(table_name, engine, if_exists='replace', index=False)
```

Los archivos CSV utilizados fueron mapeados y cargados en el volumen para poder usarlos

ğŸ“¸ Al ejecutar el dag sigue el siguiente flujo con exito:

> Si `la base de datos creada` esta vacia, el script asume que es la **primera carga**. Si ya tiene datos, realiza una carga **incremental**, ahorrando recursos.


![StgLog](./src/CargaInicialflujo.png)

Resultado: 

![Docker Bridge](https://raw.githubusercontent.com/AlexanderEmir421/Pruebas-ETL/main/docs/docker_postgres_bridge.png) CAMBIAR

---

## â˜ï¸ Paso 3: Replicar la base en la nube (Supabase)

Antes se debe crear un proyecto en Supabase, con las tablas cargadas previamente ![Codigo para crear las tablas](./SupabaseCopia.sql)respetando el modelo estrella. Este fue el modelo lÃ³gico interpretado:

```
DimProduct(productid PK, producttype)
DimCustomer(segmentid PK, city)
DimDate(dateid PK, quarter, date, monthname, month, year, quartername)
FactSales(saleid PK, segmentid FK, productid FK, dateid FK, price_per_unit, quantity_sold)
```

ğŸ“¸ MER:

![Modelo ENTIDAD RELACION](./src/MER.png)

---

## ğŸ› ï¸ Tablas auxiliares:
Realizaremos Cargas Incrementales para una mejor eficiencia del codigo ya que se realizan copias todos los dias

### `StgLog`
Esta tabla guarda registros de cuÃ¡ndo se hizo la Ãºltima carga, quÃ© tabla se actualizÃ³ y cuÃ¡l fue el Ãºltimo ID.

---

### `StgCustomer` y `StgProduct`

Estas dos tablas permiten detectar cambios en los datos de dimensiones.Comparo los registros nuevos y guardo un `estado` (activo/inactivo).

> Esto es util si borraron datos en origen. Asi evito romper la tabla `FactSales`, que necesita esas claves foraneas.

ğŸ“¸

![StgCustomer](./src/TableStgCustomer.png) ![StgDimProduct](./src/TableStgCustomer.png) CAMBIAR
---

## ğŸ”„ Flujo general del script
### Carga inicial
![Carga inicial DimDate y FactSales](./src/PrimerCarga.png) CAMBIAR

### Tablas DimDate y FactSales
### Carga incremental 
![Carga incremental DimDate y FactSales](./src/PrimerCargaIncremental.png)



### Tablas DimCustomers y DimProductos
### Carga Incremental
![Carga inicial y Incremental de DimDate y FactSales](./src/CargaInicialyIncremental.png)


### Explicacion del script de comparacion:

Se realiza un full-other join esto me permite identificar que datos de de la primera tabla no estan en la segunda y que datos de la segunda no estan en la primera 

Pandas agrega una columna _merge para ver si realizo un lef,right o full join,voy aprovechar eso ya que estamos :)

Para los datos nuevos filtraria el merge con left es la tabla origen que no hizo match con la tabla Stanging
![Datos nuevos ej con DimCustomers](./src/CargaInicialyIncremental.png) CAMBIAR

Para los datos borrados filtraria el merge con right es la tabla Stanging que no hizo match con la tabla origen
![Datos borrados ej con DimCustomers](./src/CargaInicialyIncremental.png) CAMBIAR

---


## ğŸ“… AutomatizaciÃ³n con Airflow

El DAG corre todos los dÃ­as y sigue el flujo dectectando la carga incial(solo una vez) o la carga incremental(n)

> Aunque podrÃ­a no ser estrictamente necesario la columna fecha de la tabla `stglog` me sirve para monitorear que todo corriÃ³ bien asegurando que airflow corrio cada dia.

---

## ğŸ§ª Lote de prueba

Se cargan todos los csv en postgres y supabase:

ğŸ“¸

![Insert](https://raw.githubusercontent.com/AlexanderEmir421/Pruebas-ETL/main/docs/insert_fact_test.png) CAMBIAR

La base de datos ya esta cargado por lo cual el flujo para la siguiende condicion actua asi:

ğŸ“¸

![Resultado](https://raw.githubusercontent.com/AlexanderEmir421/Pruebas-ETL/main/docs/etl_insert_detectado.png) CAMBIAR

---

## âœ… ConclusiÃ³n

Este pipeline permite una replicaciÃ³n confiable y controlada:
- Evita full refresh innecesarios
- Detecta borrados lÃ³gicos
- Deja trazabilidad
- Es liviano para correr a diario
