# ğŸ“Š Prueba TÃ©cnica â€“ Data Engineer para Business Intelligence

Este repositorio tiene como objetivo construir **pipelines de replicaciÃ³n, scraping y actualizaciÃ³n de datos**, desde mÃºltiples fuentes (bases de datos, APIs, sitios web) hacia una **base de datos en la nube**, incluyendo automatizaciÃ³n de procesos y un modelado de datos bÃ¡sico orientado a BI.


---

## ğŸ§© Objetivo General

DiseÃ±ar y automatizar pipelines de:
- ReplicaciÃ³n de base de datos (PostgreSQL)
- ExtracciÃ³n incremental desde una API pÃºblica (BCRA)
- Scraping de propiedades inmobiliarias desde la web

Con destino final en una base de datos en la nube, utilizando herramientas modernas de ingenierÃ­a de datos.

---

## ğŸ”§ TecnologÃ­as Utilizadas

- ğŸ³ Docker: ContenerizaciÃ³n de servicios
- ğŸ˜ PostgreSQL: Base de datos origen y destino
- ğŸŒ Supabase: PostgreSQL gestionado en la nube
- ğŸ Python: Lenguaje principal
- ğŸ“… Apache Airflow: Orquestador de tareas ETL
- â˜ï¸ GitHub Actions / Render: AutomatizaciÃ³n en la nube (alternativa)
- ğŸ› ï¸ LibrerÃ­as: `pandas`, `requests`, `sqlalchemy`, `psycopg2`, `dotenv`, `beautifulsoup4`, `selenium`, etc.

---

## ğŸ” Credenciales SUPABASE

- **Token pÃºblico** de acceso para consultas:
TOKEN = <inserte_token>


- **Credenciales privadas:** solicitarlas por correo a [alexanderemir421@gmail.com](mailto:alexanderemir421@gmail.com)

> TambiÃ©n podÃ©s crear tu propia base de datos en Supabase, generar un usuario y configurar el token en el archivo `.env` del repositorio,esto requiere la creacion de tablas dentro de supabase ya que no es posible crear tablas desde afuera.

## âš™ï¸ Levantar el proyecto

1. ClonÃ¡ el repositorio

```bash
git clone https://github.com/tu_usuario/data-engineer-bi.git
cd data-engineer-bi
```

2. ConfigurÃ¡ tus variables en `.env` (ver `.env.example`)

3. LevantÃ¡ los servicios con Docker Compose

```bash
docker-compose up -d
```

Esto pondrÃ¡ en marcha:
- Airflow (Web UI, Scheduler, Worker)
- PostgreSQL
- Montaje automÃ¡tico de DAGs en `/dags`

---

## ğŸ“‚ Estructura del Proyecto

```
.
â”œâ”€â”€ dags/                            # DAGs de Airflow (uno por ejercicio)
â”‚   â”œâ”€â”€ dag_replicacion.py
â”‚   â”œâ”€â”€ dag_api_bcra.py
â”‚   â””â”€â”€ dag_scraping.py
â”œâ”€â”€ ejercicio_1_replicacion/         # Scripts y documentaciÃ³n del ejercicio 1
â”‚   â”œâ”€â”€ etl_replicacion.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ ejercicio_2_api_bcra/            # Scripts y documentaciÃ³n del ejercicio 2
â”‚   â”œâ”€â”€ etl_bcra.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ ejercicio_3_scraping/            # Scripts y documentaciÃ³n del ejercicio 3
â”‚   â”œâ”€â”€ scraping_inmuebles.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ docs/                            # Diagramas, esquemas y recursos visuales
â”œâ”€â”€ docker-compose.yml               # Define los servicios del entorno
â”œâ”€â”€ requirements.txt                 # LibrerÃ­as requeridas
â””â”€â”€ README.md                        # DocumentaciÃ³n general (este archivo)
```

---

## ğŸ“˜ DocumentaciÃ³n TÃ©cnica por Ejercicio

| Ejercicio | DescripciÃ³n | DocumentaciÃ³n |
|----------|-------------|----------------|
| Ejercicio 1 | ReplicaciÃ³n de base PostgreSQL a Supabase | [Ver README](./ejercicio_1_replicacion/README.md) |
| Ejercicio 2 | Ingesta incremental de cotizaciones desde API BCRA | [Ver README](./ejercicio_2_api_bcra/README.md) |
| Ejercicio 3 | Scraping de propiedades en Posadas (Misiones) | [Ver README](./ejercicio_3_scraping/README.md) |

Cada uno de estos contiene:
- CÃ³digo ETL modular
- ExplicaciÃ³n tÃ©cnica del proceso
- AutomatizaciÃ³n (Airflow DAG)
- Resultados y/o screenshots

---

## ğŸ–¼ï¸ Diagrama General del Proyecto

![Arquitectura General](docs/arquitectura_general.png)

> MÃ¡s diagramas disponibles en la carpeta `docs/`

---

## ğŸ“¬ Contacto

ğŸ“§ [alexanderemir421@gmail.com](mailto:alexanderemir421@gmail.com)

---
